#!/usr/bin/env python3
"""–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è RAG —Å–∏—Å—Ç–µ–º—ã —Å –ø–µ—Ä–µ–¥–æ–≤—ã–º–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏ 2025."""

import asyncio
import argparse
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append('.')

import structlog

from llamacpp_server.retrieval.modern_chunker import ChunkingStrategy
from llamacpp_server.retrieval.modern_embeddings import EmbeddingProvider
from llamacpp_server.retrieval.modern_vector_store import VectorStoreType
from llamacpp_server.retrieval.modern_rag_service import ModernRAGService
from llamacpp_server.config.settings import get_settings

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = structlog.get_logger(__name__)


async def build_rag_database(
    data_path: Path,
    chunking_strategy: ChunkingStrategy = ChunkingStrategy.HYBRID,
    embedding_provider: EmbeddingProvider = EmbeddingProvider.SENTENCE_TRANSFORMERS,
    embedding_model: str = "BAAI/bge-m3",
    collection_name: str = "rag_documents",
    min_score: float = 0.1  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
) -> dict:
    """
    –ü–æ—Å—Ç—Ä–æ–∏—Ç—å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—É—é RAG –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.
    
    Args:
        data_path: –ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º
        chunking_strategy: –°—Ç—Ä–∞—Ç–µ–≥–∏—è —á–∞–Ω–∫–∏–Ω–≥–∞
        embedding_provider: –ü—Ä–æ–≤–∞–π–¥–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        embedding_model: –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        collection_name: –ò–º—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        min_score: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π score –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        
    Returns:
        –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±–∞–∑—ã
    """
    
    logger.info("üöÄ –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π RAG —Å–∏—Å—Ç–µ–º—ã",
               chunking_strategy=chunking_strategy.value,
               embedding_provider=embedding_provider.value,
               embedding_model=embedding_model,
               collection_name=collection_name)
    
    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    settings = get_settings()
    
    # –°–æ–∑–¥–∞–µ–º RAG —Å–µ—Ä–≤–∏—Å (–≤—Å–µ–≥–¥–∞ ChromaDB)
    rag_service = ModernRAGService(
        embedding_provider=embedding_provider,
        embedding_model=embedding_model,
        vector_store_type=VectorStoreType.CHROMADB,
        collection_name=collection_name,
        settings=settings
    )
    
    await rag_service.initialize()
    
    # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON —Ñ–∞–π–ª–∞
    import json
    
    with open(data_path, 'r', encoding='utf-8') as f:
        confluence_data = json.load(f)
    
    logger.info("üìÇ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã", 
               pages_count=len(confluence_data),
               source_file=str(data_path))
    
    # –°–æ–∑–¥–∞–µ–º chunker
    from llamacpp_server.retrieval.modern_chunker import ModernChunkerFactory
    
    chunker = ModernChunkerFactory.create_chunker(
        strategy=chunking_strategy,
        chunk_size=512,
        overlap=50
    )
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    all_documents = []
    
    for page in confluence_data:
        try:
            # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata = {
                "title": page.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"),
                "source": page.get("url", ""),
                "page_id": page.get("id", ""),
                "when": page.get("when", ""),
                "chunking_strategy": chunking_strategy.value,
                "embedding_provider": embedding_provider.value
            }
            
            # –ß–∞–Ω–∫–∏–Ω–≥ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            content = page.get("body", "")
            if not content.strip():
                continue
                
            chunks = await chunker.chunk_text(content, metadata)
            
            # –ì–æ—Ç–æ–≤–∏–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
            for chunk in chunks:
                doc_data = {
                    "content": chunk.content,
                    "metadata": chunk.metadata
                }
                all_documents.append(doc_data)
                
        except Exception as e:
            logger.warning("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã", 
                         title=page.get("title", "Unknown"),
                         error=str(e))
            continue
    
    logger.info("üìù –î–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã", 
               total_documents=len(all_documents))
    
    # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –±–∞—Ç—á–∞–º–∏
    stats = await rag_service.batch_add_documents(
        documents=all_documents,
        batch_size=32
    )
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫
    test_query = "–Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–∏—Å—Ç–µ–º—ã"
    logger.info("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–∞", query=test_query)
    
    test_results = await rag_service.search_relevant_context(
        query=test_query,
        k=3,
        min_score=min_score
    )
    
    logger.info("‚úÖ –¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω", 
               found_docs=len(test_results),
               min_score=min_score)
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    collection_stats = await rag_service.get_collection_stats()
    
    final_stats = {
        **stats,
        "test_results": len(test_results),
        "collection_stats": collection_stats,
        "chunking_strategy": chunking_strategy.value,
        "embedding_provider": embedding_provider.value,
        "vector_store": "ChromaDB"
    }
    
    logger.info("üéØ RAG —Å–∏—Å—Ç–µ–º–∞ —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ", **final_stats)
    
    return final_stats


def parse_arguments():
    """–ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏."""
    parser = argparse.ArgumentParser(
        description="–°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π RAG —Å–∏—Å—Ç–µ–º—ã —Å ChromaDB",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python modern_build_rag.py data/confluence.json
  python modern_build_rag.py data/confluence.json --semantic --openai
  python modern_build_rag.py data/confluence.json --hybrid --model2vec
        """
    )
    
    parser.add_argument(
        "data_path",
        type=Path,
        help="–ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏ Confluence"
    )
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è —á–∞–Ω–∫–∏–Ω–≥–∞
    chunking_group = parser.add_mutually_exclusive_group()
    chunking_group.add_argument("--semantic", action="store_true", help="–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π —á–∞–Ω–∫–∏–Ω–≥")
    chunking_group.add_argument("--title", action="store_true", help="–ß–∞–Ω–∫–∏–Ω–≥ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º")
    chunking_group.add_argument("--hybrid", action="store_true", help="–ì–∏–±—Ä–∏–¥–Ω—ã–π —á–∞–Ω–∫–∏–Ω–≥ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)")
    
    # –ü—Ä–æ–≤–∞–π–¥–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    embedding_group = parser.add_mutually_exclusive_group()
    embedding_group.add_argument("--sentence-transformers", action="store_true", help="SentenceTransformers (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)")
    embedding_group.add_argument("--model2vec", action="store_true", help="Model2Vec")
    embedding_group.add_argument("--openai", action="store_true", help="OpenAI")
    
    parser.add_argument("--collection", default="rag_documents", help="–ò–º—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏")
    parser.add_argument("--model", default="BAAI/bge-m3", help="–ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
    parser.add_argument("--min-score", type=float, default=0.1, help="–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π score –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
    
    return parser.parse_args()


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    args = parse_arguments()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —á–∞–Ω–∫–∏–Ω–≥–∞
    if args.semantic:
        chunking_strategy = ChunkingStrategy.SEMANTIC
    elif args.title:
        chunking_strategy = ChunkingStrategy.TITLE
    else:
        chunking_strategy = ChunkingStrategy.HYBRID
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    if args.model2vec:
        embedding_provider = EmbeddingProvider.MODEL2VEC
    elif args.openai:
        embedding_provider = EmbeddingProvider.OPENAI
    else:
        embedding_provider = EmbeddingProvider.SENTENCE_TRANSFORMERS
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
    if not args.data_path.exists():
        logger.error("‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω", path=str(args.data_path))
        return 1
    
    logger.info("üéØ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–±–æ—Ä–∫–∏",
               data_path=str(args.data_path),
               chunking_strategy=chunking_strategy.value,
               embedding_provider=embedding_provider.value,
               embedding_model=args.model,
               collection_name=args.collection,
               vector_store="ChromaDB")
    
    try:
        stats = await build_rag_database(
            data_path=args.data_path,
            chunking_strategy=chunking_strategy,
            embedding_provider=embedding_provider,
            embedding_model=args.model,
            collection_name=args.collection,
            min_score=args.min_score
        )
        
        logger.info("‚úÖ –°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è RAG —Å–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞!", **stats)
        return 0
        
    except Exception as e:
        logger.error("‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è RAG —Å–∏—Å—Ç–µ–º—ã", error=str(e), exc_info=True)
        return 1


if __name__ == "__main__":
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ structlog
    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_logger_name,
            structlog.stdlib.add_log_level,
            structlog.stdlib.PositionalArgumentsFormatter(),
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.StackInfoRenderer(),
            structlog.processors.format_exc_info,
            structlog.processors.UnicodeDecoder(),
            structlog.dev.ConsoleRenderer()
        ],
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        wrapper_class=structlog.stdlib.BoundLogger,
        cache_logger_on_first_use=True,
    )
    
    exit_code = asyncio.run(main()) 