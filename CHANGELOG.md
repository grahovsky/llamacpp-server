# Changelog

–í—Å–µ –∑–Ω–∞—á–∏–º—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –ø—Ä–æ–µ–∫—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä—É—é—Ç—Å—è –≤ —ç—Ç–æ–º —Ñ–∞–π–ª–µ.

–§–æ—Ä–º–∞—Ç –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
–ø—Ä–æ–µ–∫—Ç —Å–ª–µ–¥—É–µ—Ç [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [Unreleased]

### Added
- üîÑ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–æ—Ç–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –∏—Å—Ç–æ—Ä–∏–π —á–∞—Ç–∞
- üß† ChatHistoryManager –¥–ª—è —É–º–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞–º–∏
- üéÆ –ü–æ–ª–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ GPU —á–µ—Ä–µ–∑ CUDA Toolkit
- üìä –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ GPU —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
- üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
- üìè –ü–æ–¥—Å—á–µ—Ç —Ä–µ–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ —á–µ—Ä–µ–∑ llama-cpp-python
- üõ°Ô∏è –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –ø—Ä–∏ —Ä–æ—Ç–∞—Ü–∏–∏
- üìù –ü–æ–¥—Ä–æ–±–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ GPU —É—Å—Ç–∞–Ω–æ–≤–∫–µ

### Changed
- ‚ö° –£–≤–µ–ª–∏—á–µ–Ω —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å 2048 –¥–æ 4096 —Ç–æ–∫–µ–Ω–æ–≤
- üèóÔ∏è –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è ChatHistoryManager –≤ LlamaService
- üé≠ –£–ª—É—á—à–µ–Ω–∞ MockLlama —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π tokenize()
- üì¶ –û–±–Ω–æ–≤–ª–µ–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ pyproject.toml –¥–ª—è GPU –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
- üîÑ –£–ª—É—á—à–µ–Ω –ø—Ä–æ—Ü–µ—Å—Å —É—Å—Ç–∞–Ω–æ–≤–∫–∏ GPU –ø–æ–¥–¥–µ—Ä–∂–∫–∏

### Fixed
- üö´ –£—Å—Ç—Ä–∞–Ω–µ–Ω–∞ –æ—à–∏–±–∫–∞ "Requested tokens exceed context window"
- üíæ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –ø–∞–º—è—Ç—å –ø—Ä–∏ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
- üéØ –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑–µ—Ä–≤ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏

### Technical Details
- **–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ**: 4096 —Ç–æ–∫–µ–Ω–æ–≤ (–±—ã–ª–æ 2048)
- **–õ–∏–º–∏—Ç –∏—Å—Ç–æ—Ä–∏–∏**: 3000 —Ç–æ–∫–µ–Ω–æ–≤
- **–†–µ–∑–µ—Ä–≤ –¥–ª—è –æ—Ç–≤–µ—Ç–∞**: 1000 —Ç–æ–∫–µ–Ω–æ–≤
- **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**: –ò—Å—Ç–æ—Ä–∏—è 12,367 ‚Üí 24 —Ç–æ–∫–µ–Ω–∞ –ø—Ä–∏ —Ä–æ—Ç–∞—Ü–∏–∏
- **GPU –ø–æ–¥–¥–µ—Ä–∂–∫–∞**: CUDA 12.8 –Ω–∞ RTX 3070

---

## [0.1.0] - 2025-06-07

### Added
- üöÄ –ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å–µ—Ä–≤–µ—Ä–∞ llama.cpp
- üåê –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö API:
  - OpenAI API (`/v1/chat/completions`, `/v1/completions`)
  - Ollama API (`/api/chat`, `/api/generate`, `/api/tags`)
  - Open WebUI API (`/api/*`)
- üì° –°—Ç—Ä–∏–º–∏–Ω–≥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ–∫–µ–Ω –∑–∞ —Ç–æ–∫–µ–Ω–æ–º
- üèóÔ∏è Clean Architecture —Å —Å–ª–æ–∏—Å—Ç–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
- üêç Python 2025 —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã (uv, ruff, mypy, pytest)
- üîß Pydantic Settings v2 –¥–ª—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
- üìä structlog –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
- üß™ Comprehensive test suite
- üîÑ dependency-injector –¥–ª—è DI
- üõ°Ô∏è SOLID –ø—Ä–∏–Ω—Ü–∏–ø—ã –≤–æ –≤—Å–µ–º –∫–æ–¥–µ
- üé≠ MockLlama –¥–ª—è —Ä–µ–∂–∏–º–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

### Technical Stack
- **Python**: 3.11+
- **Framework**: FastAPI + uvicorn
- **LLM**: llama.cpp + llama-cpp-python
- **Architecture**: Clean Architecture
- **Config**: Pydantic Settings v2
- **Logging**: structlog
- **DI**: dependency-injector
- **Testing**: pytest + httpx
- **Code Quality**: ruff + mypy
- **Package Manager**: uv

[Unreleased]: https://github.com/user/llamacpp-server/compare/v0.1.0...HEAD
[0.1.0]: https://github.com/user/llamacpp-server/releases/tag/v0.1.0 