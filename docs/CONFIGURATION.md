# üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

–ü–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ llamacpp-server.

## –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

–í—Å–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É—é—Ç—Å—è —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º `LLAMACPP_`.

### –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

```bash
# === –ú–æ–¥–µ–ª—å ===
LLAMACPP_MODEL_PATH=models/model.gguf  # –ü—É—Ç—å –∫ GGUF –º–æ–¥–µ–ª–∏
LLAMACPP_DEV_MODE=false                # –†–µ–∂–∏–º —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ (mock –º–æ–¥–µ–ª—å)

# === –°–µ—Ä–≤–µ—Ä ===
LLAMACPP_HOST=0.0.0.0                  # IP –∞–¥—Ä–µ—Å (0.0.0.0 –¥–ª—è –≤—Å–µ—Ö –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤)
LLAMACPP_PORT=8090                     # –ü–æ—Ä—Ç —Å–µ—Ä–≤–µ—Ä–∞

# === –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ===
LLAMACPP_LOG_LEVEL=DEBUG               # DEBUG, INFO, WARNING, ERROR
LLAMACPP_VERBOSE=false                 # –ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥ llama.cpp
```

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏

```bash
# === –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ ===
LLAMACPP_N_CTX=4096                    # –†–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (—Ç–æ–∫–µ–Ω—ã)
LLAMACPP_N_BATCH=512                   # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
LLAMACPP_N_THREADS=8                   # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ CPU –ø–æ—Ç–æ–∫–æ–≤

# === –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–µ–π ===
LLAMACPP_MAX_HISTORY_TOKENS=3000       # –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞
LLAMACPP_CONTEXT_RESERVE_TOKENS=1000   # –†–µ–∑–µ—Ä–≤ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –æ—Ç–≤–µ—Ç–∞

# === –ü–∞–º—è—Ç—å ===
LLAMACPP_USE_MMAP=true                 # Memory mapping –¥–ª—è –º–æ–¥–µ–ª–∏
LLAMACPP_USE_MLOCK=false               # Memory locking
```

### GPU –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

```bash
# === CUDA ===
LLAMACPP_N_GPU_LAYERS=0                # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤ –Ω–∞ GPU (0=CPU, -1=–≤—Å–µ)
LLAMACPP_MAIN_GPU=0                    # ID –æ—Å–Ω–æ–≤–Ω–æ–π GPU
LLAMACPP_TENSOR_SPLIT="0.7,0.3"       # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –º–µ–∂–¥—É GPU (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
```

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏

```bash
# === –ì–µ–Ω–µ—Ä–∞—Ü–∏—è ===
LLAMACPP_TEMPERATURE=0.7               # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ (0.0-2.0)
LLAMACPP_CHAT_FORMAT=llama-2           # –§–æ—Ä–º–∞—Ç —á–∞—Ç–∞ (llama-2, chatml, etc.)
```

## –§–∞–π–ª .env

–í–º–µ—Å—Ç–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ–∞–π–ª `.env` –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞:

```bash
# .env —Ñ–∞–π–ª
LLAMACPP_MODEL_PATH=models/mistral-7b.gguf
LLAMACPP_N_GPU_LAYERS=20
LLAMACPP_N_CTX=4096
LLAMACPP_PORT=8090
```

## –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ –∫–æ–¥

–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–∞–∫–∂–µ –º–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ:

```python
from llamacpp_server.config.settings import get_settings

settings = get_settings()
settings.n_gpu_layers = 20
settings.temperature = 0.8
```

## –ü—Ä–∏–º–µ—Ä—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π

### –í—ã—Å–æ–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (GPU)
```bash
LLAMACPP_N_GPU_LAYERS=-1              # –í—Å—è –º–æ–¥–µ–ª—å –Ω–∞ GPU
LLAMACPP_N_CTX=8192                   # –ë–æ–ª—å—à–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
LLAMACPP_N_BATCH=1024                 # –ë–æ–ª—å—à–æ–π –±–∞—Ç—á
LLAMACPP_USE_MMAP=true
LLAMACPP_USE_MLOCK=true
```

### –≠–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏ (CPU)
```bash
LLAMACPP_N_GPU_LAYERS=0               # –¢–æ–ª—å–∫–æ CPU
LLAMACPP_N_CTX=2048                   # –ú–µ–Ω—å—à–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
LLAMACPP_N_BATCH=256                  # –ú–µ–Ω—å—à–∏–π –±–∞—Ç—á
LLAMACPP_N_THREADS=4                  # –ú–µ–Ω—å—à–µ –ø–æ—Ç–æ–∫–æ–≤
```

### –†–µ–∂–∏–º —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
```bash
LLAMACPP_DEV_MODE=true                # Mock –º–æ–¥–µ–ª—å
LLAMACPP_LOG_LEVEL=DEBUG              # –ü–æ–¥—Ä–æ–±–Ω—ã–µ –ª–æ–≥–∏
LLAMACPP_VERBOSE=true                 # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
```

### –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ GPU
```bash
LLAMACPP_N_GPU_LAYERS=30              # –ß–∞—Å—Ç–∏—á–Ω–æ –Ω–∞ GPU
LLAMACPP_MAIN_GPU=0                   # –û—Å–Ω–æ–≤–Ω–∞—è GPU
LLAMACPP_TENSOR_SPLIT="0.6,0.4"      # 60% –Ω–∞ GPU 0, 40% –Ω–∞ GPU 1
```

## –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

### –§–∞–∫—Ç–æ—Ä—ã –≤–ª–∏—è—é—â–∏–µ –Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç—å:

1. **GPU vs CPU**: GPU –≤ 5-10 —Ä–∞–∑ –±—ã—Å—Ç—Ä–µ–µ
2. **–†–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞**: –ë–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç = –º–µ–¥–ª–µ–Ω–Ω–µ–µ
3. **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤ –Ω–∞ GPU**: –ë–æ–ª—å—à–µ —Å–ª–æ–µ–≤ = –±—ã—Å—Ç—Ä–µ–µ
4. **–†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏**: –ú–µ–Ω—å—à–µ –º–æ–¥–µ–ª—å = –±—ã—Å—Ç—Ä–µ–µ

### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è:

```bash
# –î–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏
LLAMACPP_N_GPU_LAYERS=-1              # –í—Å—è –º–æ–¥–µ–ª—å –Ω–∞ GPU
LLAMACPP_N_BATCH=1024                 # –ë–æ–ª—å—à–æ–π –±–∞—Ç—á
LLAMACPP_USE_MMAP=true                # Memory mapping

# –î–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ VRAM
LLAMACPP_N_GPU_LAYERS=20              # –ß–∞—Å—Ç—å —Å–ª–æ–µ–≤ –Ω–∞ GPU
LLAMACPP_N_CTX=2048                   # –ú–µ–Ω—å—à–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
```

## –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### –õ–æ–≥–∏
```bash
# –ò–∑–º–µ–Ω–∏—Ç—å —É—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
export LLAMACPP_LOG_LEVEL=INFO

# –í–∫–ª—é—á–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–µ –ª–æ–≥–∏ llama.cpp
export LLAMACPP_VERBOSE=true
```

### –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ GPU
```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU
nvidia-smi

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ CUDA –≤ –∫–æ–¥–µ
uv run python -c "import llama_cpp; from llama_cpp import llama_cpp; print('CUDA:', llama_cpp.llama_supports_gpu_offload())"
```

## –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫

### –ü—Ä–æ–±–ª–µ–º—ã —Å –ø–∞–º—è—Ç—å—é
- –£–º–µ–Ω—å—à–∏—Ç–µ `LLAMACPP_N_CTX`
- –£–º–µ–Ω—å—à–∏—Ç–µ `LLAMACPP_N_GPU_LAYERS`
- –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ `LLAMACPP_USE_MMAP=false`

### –ú–µ–¥–ª–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
- –£–≤–µ–ª–∏—á—å—Ç–µ `LLAMACPP_N_GPU_LAYERS`
- –£–≤–µ–ª–∏—á—å—Ç–µ `LLAMACPP_N_BATCH`
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∑–∞–≥—Ä—É–∑–∫—É GPU —Å `nvidia-smi`

### –û—à–∏–±–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
- –£–º–µ–Ω—å—à–∏—Ç–µ `LLAMACPP_MAX_HISTORY_TOKENS`
- –£–≤–µ–ª–∏—á—å—Ç–µ `LLAMACPP_CONTEXT_RESERVE_TOKENS` 