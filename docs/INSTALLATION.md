# üèóÔ∏è –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞

–ü–æ—à–∞–≥–æ–≤–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ llamacpp-server.

## –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

- **Python**: 3.11 –∏–ª–∏ –≤—ã—à–µ
- **–°–∏—Å—Ç–µ–º–∞**: Linux, macOS, Windows
- **–ü–∞–º—è—Ç—å**: –º–∏–Ω–∏–º—É–º 8GB RAM –¥–ª—è –º–æ–¥–µ–ª–µ–π 7B
- **–î–∏—Å–∫**: 5-20GB –¥–ª—è –º–æ–¥–µ–ª–µ–π –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞

## –£—Å—Ç–∞–Ω–æ–≤–∫–∞

### 1. –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è

```bash
git clone <repo-url>
cd llamacpp-server
```

### 2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

#### –ë–∞–∑–æ–≤–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ (CPU)
```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–æ–ª—å–∫–æ CPU –ø–æ–¥–¥–µ—Ä–∂–∫–∏
uv sync --extra cpu
# –î–ª—è GPU
uv sync --extra gpu
```

#### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
```bash
# –í—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≤–∫–ª—é—á–∞—è dev tools
uv sync --extra all
```

#### GPU –ø–æ–¥–¥–µ—Ä–∂–∫–∞
–°–º. [GPU Setup Guide](GPU_SETUP.md) –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π.

### 3. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `.env` –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞:

```bash
# === –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ ===
LLAMACPP_MODEL_PATH=models/model.gguf
LLAMACPP_DEV_MODE=false

# === –°–µ—Ä–≤–µ—Ä ===
LLAMACPP_HOST=0.0.0.0
LLAMACPP_PORT=8090

# === –ö–æ–Ω—Ç–µ–∫—Å—Ç ===
LLAMACPP_N_CTX=4096
LLAMACPP_MAX_HISTORY_TOKENS=3000
LLAMACPP_CONTEXT_RESERVE_TOKENS=1000

# === GPU (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) ===
LLAMACPP_N_GPU_LAYERS=0  # 0=CPU, >0=GPU —Å–ª–æ–∏
LLAMACPP_MAIN_GPU=0
```

### 4. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏

```bash
# –°–æ–∑–¥–∞–π—Ç–µ –ø–∞–ø–∫—É –¥–ª—è –º–æ–¥–µ–ª–µ–π
mkdir -p models

# –ó–∞–≥—Ä—É–∑–∏—Ç–µ GGUF –º–æ–¥–µ–ª—å (–ø—Ä–∏–º–µ—Ä)
wget -O models/model.gguf https://example.com/model.gguf
```

### 5. –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫

#### –†–µ–∂–∏–º —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ (–±–µ–∑ –º–æ–¥–µ–ª–∏)
```bash
LLAMACPP_DEV_MODE=true uv run python -m llamacpp_server.main
```

#### –° —Ä–µ–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é
```bash
uv run python -m llamacpp_server.main
```

### 6. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç—ã

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è
curl http://localhost:8090/health

# –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
curl http://localhost:8090/api/tags

# –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
curl -X POST http://localhost:8090/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model": "llama", "messages": [{"role": "user", "content": "Hello!"}]}'
```

## –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫

### –ü—Ä–æ–±–ª–µ–º–∞: "–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
ls -la models/

# –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –ø—É—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤ .env
echo $LLAMACPP_MODEL_PATH
```

### –ü—Ä–æ–±–ª–µ–º–∞: "–ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –ø–∞–º—è—Ç–∏"
```bash
# –£–º–µ–Ω—å—à–∏—Ç–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç
export LLAMACPP_N_CTX=2048

# –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—å—à—É—é –º–æ–¥–µ–ª—å
```

### –ü—Ä–æ–±–ª–µ–º–∞: "–ü–æ—Ä—Ç –∑–∞–Ω—è—Ç"
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ –ø–æ—Ä—Ç —Å–≤–æ–±–æ–¥–µ–Ω
netstat -tlnp | grep 8090

# –ò–ª–∏ –∏–∑–º–µ–Ω–∏—Ç–µ –ø–æ—Ä—Ç
export LLAMACPP_PORT=8091
```

## –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

- [GPU –ø–æ–¥–¥–µ—Ä–∂–∫–∞](GPU_SETUP.md) –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
- [–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è](CONFIGURATION.md) –¥–ª—è —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
- [API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è](API.md) –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ 