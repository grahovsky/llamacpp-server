"""–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –º–æ–¥—É–ª—å –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è RAG –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã."""

import json
import uuid
from pathlib import Path
from typing import Any

import structlog

from ..config.settings import get_settings
from .modern_chunker import ChunkingStrategy, ModernSemanticChunker
from .modern_embeddings import EmbeddingProvider, ModernEmbeddingService
from .modern_vector_store import ModernVectorStoreFactory, VectorStoreType
from .protocols import Document

logger = structlog.get_logger(__name__)


def preprocess_text(text: str) -> str:
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞."""
    if not text:
        return ""

    import re
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    text = text.replace("false", "").replace("true", "")
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r'\s+', ' ', text)
    text = text.strip()

    return text


class ModernRAGBuilder:
    """–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –ø–æ—Å—Ç—Ä–æ–∏—Ç–µ–ª—å RAG –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã —Å –ª—É—á—à–∏–º–∏ –ø—Ä–∞–∫—Ç–∏–∫–∞–º–∏ 2025."""

    def __init__(
        self,
        # Chunking settings
        chunking_strategy: ChunkingStrategy = ChunkingStrategy.HYBRID,
        chunk_size: int = 512,
        overlap_size: int = 50,

        # Embedding settings
        embedding_provider: EmbeddingProvider = EmbeddingProvider.SENTENCE_TRANSFORMERS,
        embedding_model: str = "BAAI/bge-m3",

        # Vector store settings
        vector_store_type: VectorStoreType = VectorStoreType.CHROMADB,
        collection_name: str = "rag_documents",

        # Processing settings
        batch_size: int = 32,
        test_mode: bool = False
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ RAG –±–∏–ª–¥–µ—Ä–∞.

        Args:
            chunking_strategy: –°—Ç—Ä–∞—Ç–µ–≥–∏—è —á–∞–Ω–∫–∏–Ω–≥–∞ (semantic, title, hybrid)
            chunk_size: –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞
            overlap_size: –†–∞–∑–º–µ—Ä –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è
            embedding_provider: –ü—Ä–æ–≤–∞–π–¥–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            embedding_model: –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            vector_store_type: –¢–∏–ø –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
            collection_name: –ò–º—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
            test_mode: –†–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        self.chunking_strategy = chunking_strategy
        self.chunk_size = chunk_size
        self.overlap_size = overlap_size
        self.embedding_provider = embedding_provider
        self.embedding_model = embedding_model
        self.vector_store_type = vector_store_type
        self.collection_name = collection_name
        self.batch_size = batch_size
        self.test_mode = test_mode

        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.settings = get_settings()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.chunker: ModernSemanticChunker | None = None
        self.embedding_service: ModernEmbeddingService | None = None
        self.vector_store = None

    async def _initialize_components(self) -> None:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤."""
        logger.info("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö RAG –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —á–∞–Ω–∫–µ—Ä
        self.chunker = ModernSemanticChunker(
            strategy=self.chunking_strategy,
            chunk_size=self.chunk_size,
            overlap=self.overlap_size
        )
        await self.chunker.initialize()
        logger.info("‚úÖ –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π —á–∞–Ω–∫–µ—Ä –≥–æ—Ç–æ–≤", strategy=self.chunking_strategy.value)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ —Å–µ—Ä–≤–∏—Å
        embedding_config = {
            "provider_type": self.embedding_provider.value,
            "model_name": self.embedding_model
        }

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
        if self.embedding_provider == EmbeddingProvider.MODEL2VEC:
            embedding_config["model_name"] = "minishlab/potion-base-8M"  # –ë—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å
        elif self.embedding_provider == EmbeddingProvider.OPENAI:
            embedding_config["api_key"] = self.settings.openai_api_key

        self.embedding_service = ModernEmbeddingService(**embedding_config)
        await self.embedding_service.initialize()
        logger.info("‚úÖ –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ —Å–µ—Ä–≤–∏—Å –≥–æ—Ç–æ–≤",
                   provider=self.embedding_provider.value,
                   model=self.embedding_model)

        # –°–æ–∑–¥–∞–µ–º vector store
        store_config = {
            "collection_name": self.collection_name,
            "persist_path": getattr(self.settings, 'chromadb_path', './data/chromadb')
        }
        
        self.vector_store = ModernVectorStoreFactory.create_store("chroma", **store_config)
        logger.info("‚úÖ –í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å–æ–∑–¥–∞–Ω–æ", type="ChromaDB")

    async def build_from_confluence_data(
        self,
        input_file: Path,
        output_dir: Path | None = None
    ) -> dict[str, Any]:
        """
        –ü–æ—Å—Ç—Ä–æ–∏—Ç—å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—É—é RAG –±–∞–∑—É –∏–∑ –¥–∞–Ω–Ω—ã—Ö Confluence.

        Args:
            input_file: –§–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ Confluence
            output_dir: –í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ modern —Ä–µ–∂–∏–º–µ)

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è
        """
        logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π RAG –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        await self._initialize_components()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        logger.info("üìñ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ Confluence", file=str(input_file))
        with open(input_file, encoding='utf-8') as f:
            confluence_data = json.load(f)

        if self.test_mode and len(confluence_data) > 5:
            confluence_data = confluence_data[:5]
            logger.info("üß™ –¢–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º: –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 5 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

        logger.info("üìä –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã", total_pages=len(confluence_data))

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
        documents = await self._process_documents(confluence_data)
        logger.info("üìÑ –î–æ–∫—É–º–µ–Ω—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã", total_chunks=len(documents))

        # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
        stats = await self._create_embeddings_and_store(documents)

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫
        if self.test_mode:
            await self._test_modern_search()

        logger.info("üéâ –°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è RAG –±–∞–∑–∞ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞!")
        return stats

    async def _process_documents(self, confluence_data: list[dict[str, Any]]) -> list[Document]:
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ Confluence —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏."""
        documents = []

        for page in confluence_data:
            content = page.get("page_content", "")
            metadata = page.get("metadata", {})

            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç
            content = preprocess_text(content)
            if not content or len(content) < 50:
                logger.debug("–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç", title=metadata.get("title", ""))
                continue

            title = metadata.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è")
            source = metadata.get("source", "")
            page_id = metadata.get("id", "")

            # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            base_metadata = {
                "title": title,
                "source": source,
                "page_id": page_id,
                "when": metadata.get("when", ""),
                "chunking_strategy": self.chunking_strategy.value,
                "embedding_provider": self.embedding_provider.value
            }

            # –°–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ —á–∞–Ω–∫–∏–Ω–≥ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
            logger.debug("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º —á–∞–Ω–∫–µ—Ä–æ–º",
                        title=title,
                        strategy=self.chunking_strategy.value)

            chunks_with_metadata = await self.chunker.chunk_document(
                content=content,
                metadata=base_metadata
            )

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ Document –æ–±—ä–µ–∫—Ç—ã
            for chunk_data in chunks_with_metadata:
                doc = Document(
                    id=str(uuid.uuid4()),
                    content=chunk_data["content"],
                    metadata=chunk_data["metadata"]
                )
                documents.append(doc)

            logger.debug("–î–æ–∫—É–º–µ–Ω—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω",
                        title=title,
                        original_length=len(content),
                        chunks_count=len(chunks_with_metadata))

        return documents

    async def _create_embeddings_and_store(self, documents: list[Document]) -> dict[str, Any]:
        """–°–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ."""
        logger.info("üß† –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ",
                   total_docs=len(documents))

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∞–º–∏ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        batch_stats = []
        total_processed = 0

        for i in range(0, len(documents), self.batch_size):
            batch = documents[i:i + self.batch_size]
            batch_num = i // self.batch_size + 1
            total_batches = (len(documents) + self.batch_size - 1) // self.batch_size

            logger.info(f"üì¶ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á {batch_num}/{total_batches}",
                       batch_size=len(batch))

            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            texts = [doc.content for doc in batch]
            embeddings = await self.embedding_service.embed_batch(texts)

            # –î–æ–±–∞–≤–ª—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º
            for doc, embedding in zip(batch, embeddings, strict=False):
                doc.embedding = embedding

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–∞—Ç—á –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
            await self.vector_store.add_documents(batch)

            total_processed += len(batch)
            batch_stats.append({
                "batch_num": batch_num,
                "docs_processed": len(batch),
                "total_processed": total_processed
            })

            logger.info(f"‚úÖ –ë–∞—Ç—á {batch_num} –æ–±—Ä–∞–±–æ—Ç–∞–Ω",
                       processed=len(batch),
                       total_progress=f"{total_processed}/{len(documents)}")

        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = {
            "total_documents": len(documents),
            "total_batches": len(batch_stats),
            "chunking_strategy": self.chunking_strategy.value,
            "embedding_provider": self.embedding_provider.value,
            "vector_store_type": self.vector_store_type.value,
            "collection_name": self.collection_name,
            "success": True
        }

        logger.info("‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–æ–∑–¥–∞–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã", **stats)
        return stats

    async def _test_modern_search(self) -> None:
        """–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫."""
        logger.info("üîç –ù–∞—á–∏–Ω–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞")

        test_queries = [
            "–ö–∞–∫ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Jenkins?",
            "–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã Docker",
            "–ß—Ç–æ —Ç–∞–∫–æ–µ Kubernetes?",
            "Git –∫–æ–º–∞–Ω–¥—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ—Ç–∫–∞–º–∏",
            "HTTP –∫–æ–¥—ã –æ—Ç–≤–µ—Ç–æ–≤ API"
        ]

        for i, query in enumerate(test_queries, 1):
            logger.info(f"–ó–∞–ø—Ä–æ—Å {i}: {query}")

            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞
            query_embedding = await self.embedding_service.embed_text(query)

            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
            results = await self.vector_store.search(query_embedding, k=3)

            if results:
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
                for j, result in enumerate(results, 1):
                    doc = result.document
                    score = result.score
                    title = doc.metadata.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
                    preview = doc.content[:150].replace('\n', ' ') + "..." if len(doc.content) > 150 else doc.content
                    logger.info(f"  –î–æ–∫—É–º–µ–Ω—Ç {j} (score: {score:.3f}): {title}")
                    logger.info(f"    {preview}")
            else:
                logger.warning(f"‚ùå –î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {query}")


        logger.info("‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")


async def build_modern_rag_from_confluence(
    input_file: str = "data/confluence_data.json",
    output_dir: str = "data/modern_rag_index",
    chunking_strategy: ChunkingStrategy = ChunkingStrategy.HYBRID,
    embedding_provider: EmbeddingProvider = EmbeddingProvider.SENTENCE_TRANSFORMERS,
    vector_store_type: VectorStoreType = VectorStoreType.CHROMADB,
    test_mode: bool = False
) -> dict[str, Any]:
    """
    –ü–æ—Å—Ç—Ä–æ–∏—Ç—å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—É—é RAG –±–∞–∑—É –∏–∑ –¥–∞–Ω–Ω—ã—Ö Confluence.

    –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –æ–±—Ä–∞—Ç–Ω—É—é —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º API.
    """
    builder = ModernRAGBuilder(
        chunking_strategy=chunking_strategy,
        embedding_provider=embedding_provider,
        vector_store_type=vector_store_type,
        test_mode=test_mode
    )

    return await builder.build_from_confluence_data(
        input_file=Path(input_file),
        output_dir=Path(output_dir) if output_dir else None
    )
